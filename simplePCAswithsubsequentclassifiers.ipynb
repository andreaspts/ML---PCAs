{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle component analysis for data compression\n",
    "\n",
    "In the following we use the concept of principle component analysis (PCA). For information on PCA, we refer to https://en.wikipedia.org/wiki/Principal_component_analysis and for a discussion on the python implementation see https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60.\n",
    "\n",
    "The data to be analyzed captures mobile phone user motion information and can be downloaded from: https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones/data.\n",
    "\n",
    "# Training models after PCA\n",
    "\n",
    "In this notebook, we seek to use the results of the PCA to train various classification models (logistic regression, kNN, SVM, Naive Bayes, Decision Tree and Random Forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from helper import plot_classifier #helper.py is saved in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv.bz2\")\n",
    "test = pd.read_csv(\"./test.csv.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variables\n",
    "X_train = train.drop(\"subject\", axis = 1).drop(\"Activity\", axis = 1) #drop two last columns\n",
    "Y_train = train[\"Activity\"]\n",
    "\n",
    "X_test = test.drop(\"subject\", axis = 1).drop(\"Activity\", axis = 1) #drop two last columns\n",
    "Y_test = test[\"Activity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceed with PCA (reduce dimensions)\n",
    "pca = PCA() #PCA for all components!\n",
    "pca.fit(X_train) #you are fitting PCA on the training set only\n",
    "\n",
    "X_transformed = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50781172 0.0658068  0.02806437 0.02503953 0.01888285 0.01724006\n",
      " 0.01371011 0.01199078 0.0099586  0.00965087]\n",
      "The first 10 principle components account for 70.81556875869077 percent of the overall variance.\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_[:10]) #to give the variance ratios for the first 10 pcs\n",
    "\n",
    "print(\"The first 10 principle components account for \" + str(100*np.sum(pca.explained_variance_ratio_[:10])) + \" percent of the overall variance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print pcs\n",
    "#pca.components_[0] #for the first pc\n",
    "pca.components_[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of a logistic regression model after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceed with PCA (reduce dimensions)\n",
    "pca = PCA(n_components = 10) #break down 561 columns/axes down to 10!\n",
    "pca.fit(X_train) #you are fitting PCA on the training set only\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "X_test_transformed = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5829657278588395\n",
      "--- 0.06118583679199219 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andreas/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/Andreas/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#train logistic regression model on PCA reduced data\n",
    "#one - vs - all classification\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "classifier.fit(X_train_transformed, Y_train)\n",
    "\n",
    "Y_predicted = classifier.predict(X_test_transformed) #to predict if successful or not\n",
    "\n",
    "#score the quality of the prediction\n",
    "print(classifier.score(X_test_transformed, Y_test))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andreas/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/Andreas/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9643705463182898\n",
      "--- 11.682186841964722 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train logistic regression model on original data\n",
    "#one - vs - all classification\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier2 = LogisticRegression()\n",
    "classifier2.fit(X_train, Y_train)\n",
    "\n",
    "print(classifier2.score(X_test, Y_test))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that data compression achieved by PCA leads to drastic speed improvement for the learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of a SVM model after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceed with PCA (reduce dimensions)\n",
    "pca = PCA(n_components = 10) #break down 561 columns/axes down to 10!\n",
    "pca.fit(X_train) #you are fitting PCA on the training set only\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "X_test_transformed = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.35493722429589414\n",
      "--- 7.8921730518341064 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train SVM RBF kernel classifier on PCA reduced data\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#Kernel form K(x,x')=exp(-||x-x'||^2/(2gamma^2))\n",
    "#gamma large: kernel strongly peaked, gamma small: kernel slowly decaying wide peak\n",
    "#C value as for linear kernels modulates emphasis of landmark data points\n",
    "classifier = SVC(kernel = \"rbf\", gamma = 1, C = 1)\n",
    "\n",
    "classifier.fit(X_train_transformed, Y_train)\n",
    "\n",
    "Y_predicted = classifier.predict(X_test_transformed)\n",
    "\n",
    "print(\"Score: \" + str(classifier.score(X_test_transformed, Y_test)))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18221920597217509\n",
      "--- 95.60716915130615 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train SVM RBF kernel classifier on original data\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier2 = SVC(kernel = \"rbf\", gamma = 1, C = 1)\n",
    "classifier2.fit(X_train, Y_train)\n",
    "\n",
    "print(classifier2.score(X_test, Y_test))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of a kNN model after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceed with PCA (reduce dimensions)\n",
    "pca = PCA(n_components = 10) #break down 561 columns/axes down to 10!\n",
    "pca.fit(X_train) #you are fitting PCA on the training set only\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "X_test_transformed = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8171021377672208\n",
      "--- 0.20365166664123535 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train KNN classifier on PCA reduced data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5) #standard is n_neighbors = 5\n",
    "\n",
    "classifier.fit(X_train_transformed, Y_train)\n",
    "\n",
    "Y_predicted = classifier.predict(X_test_transfored)\n",
    "\n",
    "print(\"Score: \" + str(classifier.score(X_test_transformed, Y_test)))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8917543264336614\n",
      "--- 22.89915108680725 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train KNN classifier on original data\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier2 = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier2.fit(X_train, Y_train)\n",
    "\n",
    "print(classifier2.score(X_test, Y_test))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of a decision tree model after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceed with PCA (reduce dimensions)\n",
    "pca = PCA(n_components = 10) #break down 561 columns/axes down to 10!\n",
    "pca.fit(X_train) #you are fitting PCA on the training set only\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "X_test_transformed = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7689175432643366\n",
      "--- 0.2121567726135254 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train decision tree classifier on PCA reduced data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "\n",
    "classifier.fit(X_train_transformed, Y_train)\n",
    "\n",
    "Y_predicted = classifier.predict(X_test_transformed)\n",
    "\n",
    "print(\"Score: \" + str(classifier.score(X_test_transformed, Y_test)))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8544282321004412\n",
      "--- 7.132295846939087 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train decision tree classifier on original data\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier2 = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "classifier2.fit(X_train, Y_train)\n",
    "\n",
    "print(classifier2.score(X_test, Y_test))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of a random forest model after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceed with PCA (reduce dimensions)\n",
    "pca = PCA(n_components = 10) #break down 561 columns/axes down to 10!\n",
    "pca.fit(X_train) #you are fitting PCA on the training set only\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "X_test_transformed = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7994570749915167\n",
      "--- 0.4485588073730469 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train random forest classifier on PCA reduced data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier = RandomForestClassifier(criterion = \"entropy\", n_estimators = 10)\n",
    "\n",
    "classifier.fit(X_train_transformed, Y_train)\n",
    "\n",
    "Y_predicted = classifier.predict(X_test_transformed)\n",
    "\n",
    "print(\"Score: \" + str(classifier.score(X_test_transformed, Y_test)))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8866644044791313\n",
      "--- 2.3397629261016846 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train random forest classifier on original data\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier2 = RandomForestClassifier(criterion = \"entropy\", n_estimators = 10)\n",
    "classifier2.fit(X_train, Y_train)\n",
    "\n",
    "print(classifier2.score(X_test, Y_test))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of a Naive Bayes (GaussianNB) model after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceed with PCA (reduce dimensions)\n",
    "pca = PCA(n_components = 10) #break down 561 columns/axes down to 10!\n",
    "pca.fit(X_train) #you are fitting PCA on the training set only\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "X_test_transformed = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7923311842551748\n",
      "--- 0.03618884086608887 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train naive Bayes classifier using GaussianNB on PCA reduced data\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(X_train_transformed, Y_train)\n",
    "\n",
    "Y_predicted = classifier.predict(X_test_transformed)\n",
    "\n",
    "print(\"Score: \" + str(classifier.score(X_test_transformed, Y_test)))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n",
      "--- 0.2728719711303711 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#train naive Bayes classifier on original data\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier2 = GaussianNB()\n",
    "classifier2.fit(X_train, Y_train)\n",
    "\n",
    "print(classifier2.score(X_test, Y_test))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the training on the PCA reduced data is much faster. In most cases it gives even better results than training on the original data. Results in this notebook could be improved by increasing the number of principle components to capture more of the variance of the original data (while still trying to train faster). Standardly, hyperparameter optimization with grid search could be mounted to further improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
